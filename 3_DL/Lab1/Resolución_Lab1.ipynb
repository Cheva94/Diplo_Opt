{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYg4jx_iZ3Ey"
      },
      "source": [
        "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)\n",
        "\n",
        "## Introducción al aprendizaje profundo\n",
        "\n",
        "### Trabajo práctico entregable 1/2 (materia completa)\n",
        "\n",
        "- **Estudiantes:**\n",
        "    - [Chevallier-Boutell, Ignacio José.](https://www.linkedin.com/in/nachocheva/)\n",
        "    - Gastelu, Gabriela.\n",
        "    - Santos, Maricel.\n",
        "    - Spano, Marcelo.\n",
        "\n",
        "- **Docentes:**\n",
        "    - Johanna Analiz Frau (Mercado Libre).\n",
        "    - Nindiría Armenta Guerrero (fyo).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81o1pr1wZ3E2"
      },
      "source": [
        "## Librerías y dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkfYanqJZ3E3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "# Configuración del dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Para que todo sea reproducible\n",
        "torch.manual_seed(1994)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTxfPCoFZ3E4",
        "outputId": "98e051e9-3505-405b-a03c-53995be9f685"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if not IN_COLAB:\n",
        "    # Script de funciones necesarias\n",
        "    from utyls_DL import *\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n",
        "    # Dataset\n",
        "    df = pd.read_csv('diabetes_binary_5050split_health_indicators_BRFSS2015.csv')\n",
        "else:\n",
        "    # Script de funciones necesarias\n",
        "    !wget https://raw.githubusercontent.com/Cheva94/Diplo_Opt/main/3_DL/Lab1/utyls_DL.py\n",
        "    from utyls_DL import *\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n",
        "    # Dataset\n",
        "    url = 'https://raw.githubusercontent.com/Cheva94/Diplo_Opt/main/3_DL/Lab1/diabetes_binary_5050split_health_indicators_BRFSS2015.csv'\n",
        "    df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6ufcuoZ3E4"
      },
      "source": [
        "---\n",
        "# Descripción y preprocesamiento del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhY9QjkD3cIr"
      },
      "source": [
        "## Descripción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkXf37kzZ3E5"
      },
      "source": [
        "El BRFSS (Sistema de Vigilancia de Factores de Riesgo del Comportamiento) es una encuesta telefónica relacionada con la salud que los CDC (Centros para Control y prevención de Enfermedades) recopilan anualmente, desde 1984. Cada año, la encuesta recopila respuestas de más de 400.000 estadounidenses sobre conductas de riesgo relacionadas con la salud, enfermedades crónicas y el uso de servicios preventivos.\n",
        "\n",
        "Los datos que usaremos corresponden al año 2015. El dataset original consta de 441.455 personas y tiene 330 características, las cuales son preguntas formuladas directamente a los participantes o variables calculadas en función de las respuestas de los participantes. Particularmente, el csv que utilizaremos tiene ya una limpieza, quedando 70692 respuestas, donde la mitad no tienen diabetes y la otra mitad tienen prediabetes o diabetes propiamente dicha. La variable objetivo (`Diabetes_binary`) es binaria: 0 corresponde a ausencia de diabetes y 1 corresponde a prediabetes o diabetes. Además, el dataset está balanceado y consta de 21 características. Todas las variables son numéricas (de punto flotante) y no se presentan valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "apPsDlraZ3E5",
        "outputId": "a148c9ce-702c-4eb2-bcac-765bbf50d00a"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "\n",
        "print('\\n\\n ###-------------------------------------### \\n Distribución de Diabetes_binary:')\n",
        "display(df['Diabetes_binary'].value_counts())\n",
        "\n",
        "print('\\n\\n ###-------------------------------------### \\n Pequeña muestra del dataset:')\n",
        "df.sample(5, random_state=1994)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPR1H0xrZ3E6"
      },
      "source": [
        "Al considerar la cantidad de valores únicos presentes en cada variable, vemos que hay 14 de las 21 características son binarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "59DY16WOZ3E6",
        "outputId": "3d9a3747-d956-4e25-ed4e-28718ade8560"
      },
      "outputs": [],
      "source": [
        "nunique = df.nunique()\n",
        "display(nunique)\n",
        "\n",
        "cols_binary = [x for x in df.columns if (nunique[x] == 2) & (x != 'Diabetes_binary')]\n",
        "cols_non_binary = [x for x in df.columns if (x not in cols_binary) & (x != 'Diabetes_binary')]\n",
        "\n",
        "print(f'Hay {len(cols_binary)} features binarias y {len(cols_non_binary)} no binarias.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj5fnFzQZ3E7"
      },
      "source": [
        "Considerando las variables binarias, tenemos 5 que están relativamente balanceadas (`HighBP`, `HighChol`, `Smoker`, `Fruits` y `Sex`), mientras que el resto toma valores más extremos. El significado de las variables es el siguiente:\n",
        "- `HighBP`: tiene presión sanguínea alta, donde 0 es no y 1 es sí.\n",
        "- `HighChol`: tiene colesterol alto, donde 0 es no y 1 es sí.\n",
        "- `CholCheck`: se controló el colesterol en los últimos 5 años, donde 0 es no y 1 es sí.\n",
        "- `Smoker`: fumó al menos 100 cigarrillos a lo largo de su vida, donde 0 es no y 1 es sí.\n",
        "- `Stroke`: tuvo un ACV, donde 0 es no y 1 es sí.\n",
        "- `HeartDiseaseorAttack`: tiene enfermedades coronarias o ataques cardíacos, donde 0 es no y 1 es sí.\n",
        "- `PhysActivity`: realizó actividad física en los últimos 30 días, donde 0 es no y 1 es sí.\n",
        "- `Fruits`: consume al menos 1 fruta al día, donde 0 es no y 1 es sí.\n",
        "- `Veggies`: consume al menos 1 vegetal al día, donde 0 es no y 1 es sí.\n",
        "- `HvyAlcoholConsump`: consumo excesivo de alcohol (más de 14 bebidas en caso de varones o más de 7 bebidas en caso de mujeres), donde 0 es no y 1 es sí.\n",
        "- `AnyHealthcare`: posee algún tipo de cobertura médica, donde 0 es no y 1 es sí.\n",
        "- `NoDocbcCost`: tuvo la necesidad de ir al médico en el último año, pero no fue por el costo, donde 0 es no y 1 es sí.\n",
        "- `DiffWalk`: posee dificultad para caminar o subir escaleras, donde 0 es no y 1 es sí.\n",
        "- `Sex`: sexo, donde 0 es mujer y 1 es varon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fe7-k1dpZ3E7",
        "outputId": "cfb58aa8-cac6-41bc-df7a-eaaaad5e8111"
      },
      "outputs": [],
      "source": [
        "display(df[cols_binary].mean()*100)\n",
        "\n",
        "_, axs = plt.subplots(2, 7, figsize=(35, 10))\n",
        "for cat in range(7):\n",
        "    sns.histplot(data=df, x=cols_binary[cat], ax=axs[0, cat])\n",
        "    axs[0, cat].set_ylabel('')\n",
        "    sns.histplot(data=df, x=cols_binary[cat+7], ax=axs[1, cat])\n",
        "    axs[1, cat].set_ylabel('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azrSAo0YZ3E8"
      },
      "source": [
        "Pasando ahora a las 7 características no binarias, su significado es el siguiente:\n",
        "- `BMI`: índice de masa corporal, donde debajo de 18.5 se considera por debajo del peso ideal, entre 18.5 y 24.9 es un peso saludable, de 25.0 a 29.9 es sobrepeso y por encima de 30.0 es obesidad.\n",
        "- `GenHlth`: autopercepción del estado general de salud, donde 1 es excelente, 2 es muy bueno, 3 es bueno, 4 es malo y 5 es muy malo.\n",
        "- `MentHlth`: cuántos de los últimos 30 días tuvo una mala salud mental.\n",
        "- `PhysHlth`: cuántos de los últimos 30 días tuvo una herida o enfermedad física.\n",
        "- `Age`: categorización de edades en 13 niveles, donde 1 va desde 18 hasta 24, luego toma de a 5 años hasta llegar a la categoría 13 para 80 años o más.\n",
        "- `Education`: categorización de niveles de estudio en 6 niveles, donde 1 es nunca fue a la escuela o sólo al jardín y 6 es que asistió a la universidad 4 años o más.\n",
        "- `Income`: categorización de niveles de ingreso en 8 niveles, donde 1 es menos de $ 10.000 dólares, luego toma de a $5.000 dólares hasta llegar a 8 para $75.000 o más.\n",
        "\n",
        "Vemos que `MentHlth` y `PhysHlth` presentan una dispersión de datos mucho mayor a la media. Además, el rango de valores posibles es diferente para cada una de las variables. Al comparar las distribuciones para cada variable en función de la variable objetivo, se aprecian diferencias en general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dQHL4f1PZ3E8",
        "outputId": "cf7effc6-8800-4bbc-b0f8-f346c482bf08"
      },
      "outputs": [],
      "source": [
        "display(df[cols_non_binary].describe())\n",
        "\n",
        "\n",
        "_, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
        "for cat in range(4):\n",
        "    sns.kdeplot(data=df, x=cols_non_binary[cat], hue='Diabetes_binary', ax=axs[0, cat])\n",
        "    axs[0, cat].set_ylabel('')\n",
        "    axs[0, cat].grid()\n",
        "\n",
        "for cat in range(3):\n",
        "    sns.kdeplot(data=df, x=cols_non_binary[cat+4], hue='Diabetes_binary', ax=axs[1, cat])\n",
        "    axs[1, cat].set_ylabel('')\n",
        "    axs[1, cat].grid()\n",
        "\n",
        "axs[1, 3].set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH806jES3cIy"
      },
      "source": [
        "## Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tmz2Q5o3cIz"
      },
      "source": [
        "Creamos los tensores de features y target, escalando los datos entre 0 y 1 para las variables no binarias. Luego, creamos un TensorDataset a partir de los tensores de features y target. Finalmente, dividimos los datos para entrenar, validar y testear, y creamos los cargadores de datos para leer los datos por mini-batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4kPyJfR3cI0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, BATCH_SIZE)\n",
        "\n",
        "n_inputs = np.prod(np.array(Data_train[0][0].shape))\n",
        "n_outputs = df['Diabetes_binary'].nunique()\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3uO5LOp3cI1"
      },
      "source": [
        "---\n",
        "# Small MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqQ18h673cI1"
      },
      "source": [
        "## Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmcwGhbv3cI2"
      },
      "outputs": [],
      "source": [
        "class SmallMLP(nn.Module):\n",
        "    '''\n",
        "    Modelo fully-connected con 5 capas ocultas, teniendo n_hidden neuronas en \n",
        "    cada una de ellas. Se incluye además la posibilidad de aplicar un mismo \n",
        "    dropout a todas las capas (tanto la de entrada como las ocultas).\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_inputs, n_outputs, n_hidden, activation_function, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.drop0 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden1 = nn.Linear(n_inputs, n_hidden)\n",
        "        self.activ1 = activation_function\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ2 = activation_function\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden3 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ3 = activation_function\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden4 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ4 = activation_function\n",
        "        self.drop4 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden5 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ5 = activation_function\n",
        "        self.drop5 = nn.Dropout(dropout)\n",
        "\n",
        "        self.output = nn.Linear(n_hidden, n_outputs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.drop0(x)\n",
        "\n",
        "        x = self.activ1(self.hidden1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.activ2(self.hidden2(x))\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.activ3(self.hidden3(x))\n",
        "        x = self.drop3(x)\n",
        "\n",
        "        x = self.activ4(self.hidden3(x))\n",
        "        x = self.drop4(x)\n",
        "\n",
        "        x = self.activ5(self.hidden3(x))\n",
        "        x = self.drop5(x)\n",
        "\n",
        "        x = self.output(x)  # Output Layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqaaTQ2R3cI3"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "baseline_param = {\n",
        "    'nH': 3,\n",
        "    'AF': nn.Sigmoid(),\n",
        "    'GD': optim.SGD,\n",
        "    'LR': 0.1,\n",
        "    'Mom': 0.9\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a9VW-Dv3cI4",
        "outputId": "e6c989ec-2749-4527-9fc4-fed1c413a65b"
      },
      "outputs": [],
      "source": [
        "baseline_exp = []\n",
        "# Instanciamos el modelo\n",
        "model = SmallMLP(n_inputs, n_outputs, baseline_param['nH'], baseline_param['AF'])\n",
        "# Definimos el optimizador\n",
        "optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "# Corremos el baseline\n",
        "experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "baseline_exp.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "7yacizJ83cI5",
        "outputId": "ac47538b-5373-48f7-9978-e059165fa55b"
      },
      "outputs": [],
      "source": [
        "# plot_results(EPOCHS, f'SmallMLP/Baseline_Epocas-{EPOCHS}.csv', baseline_exp)\n",
        "plot_results(100, 'SmallMLP/Baseline_Epocas-100.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestro baseline con esta red pequeña (5 capas ocultas con 3 neuronas por capa), es bastante pobre. Por un lado, el costo de entrenamiento es prácticamente constante y, además, el costo de validación es muy errático. Esto se ve reflejando en las métricas, ya que osculan a lo largo de todas las épocas, sin alncazar alguna estabilización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17fSO_O23cI5"
      },
      "source": [
        "## Estudio de la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "activation_functions = {\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mcn0BgA3cI6",
        "outputId": "71fd36c1-6335-42e9-b573-ddda599e3412"
      },
      "outputs": [],
      "source": [
        "ActFunc_Exps1 = []\n",
        "\n",
        "for key in activation_functions.keys():\n",
        "    print(f'\\n\\n Corriendo con {key}')\n",
        "    model = SmallMLP(n_inputs, n_outputs, baseline_param['nH'], activation_functions[key])\n",
        "    optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    ActFunc_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "9SGlfm8l3cI6",
        "outputId": "9e23d625-bb77-43d1-b9a9-055fbd916548"
      },
      "outputs": [],
      "source": [
        "# plot_results(EPOCHS, f'SmallMLP/ActFunc_Epocas-{EPOCHS}.csv', ActFunc_Exps1)\n",
        "plot_results(100, 'SmallMLP/ActFunc_Epocas-100.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo primero que analizamos es qué ocurre al variar la función de activación. La sigmoide es la función de activación utilizada en el baseline. Vemos que las otras 3 mejoran bastante respecto a la sigmoide. Enfocándonos en las 3 nuevas funciones de activación, tenemos que la ReLU tiene bastantes saltos en el costo de validación, correspondiéndose con saltos en las métricas, mientras que la Tanh resulta ser la de mayor estabilidad, alcanzando dicha estabilidad en una menor cantidad de épocas (~30) respecto a LeakyReLU (~80). También se observa una mejor correspondencia entre los costes de entrenamiento y validación para Tanh que para LeakyReLU. Decidimos quedarnos con Tanh a pesar de que ReLU y LeakyReLU alcancen métricas un 2% mayores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py-hG15c3cI6"
      },
      "source": [
        "## Estudio del optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ActFunc_best1 = nn.Tanh()\n",
        "optims = [optim.SGD, optim.Adagrad, optim.RMSprop, optim.Adam]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bn0Qrtp3cI7"
      },
      "outputs": [],
      "source": [
        "Optim_Exps1 = []\n",
        "\n",
        "for opt in optims:\n",
        "    print(f'\\n\\n Corriendo con {opt}')\n",
        "    model = SmallMLP(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1)\n",
        "    if opt == optim.SGD:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Optim_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPwjc2L3cI7"
      },
      "outputs": [],
      "source": [
        "plot_results(EPOCHS, f'SmallMLP/Optimizadores_Epocas-{EPOCHS}.csv', Optim_Exps1)\n",
        "# plot_results(100, 'SmallMLP/Optimizadores_Epocas-100.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp66JoSR3cI7"
      },
      "source": [
        "## Estudio de la tasa de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Optim_best1 = optim.Adagrad\n",
        "alpha = [0.1, 0.01, 0.001, 0.0001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBoOs6vV3cI8"
      },
      "outputs": [],
      "source": [
        "LR_Exps1 = []\n",
        "\n",
        "for LR in alpha:\n",
        "    print(f'\\n\\n Corriendo con {LR}')\n",
        "    model = SmallMLP(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1)\n",
        "    if Optim_best1 == optim.SGD:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    LR_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnNDmH3B3cI8"
      },
      "outputs": [],
      "source": [
        "plot_results(EPOCHS, f'SmallMLP/LR_Epocas-{EPOCHS}.csv', LR_Exps1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWoJ8Jog3cI8"
      },
      "source": [
        "## Estudio del tamaño de lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LR_best1 = 0.1\n",
        "batches = [32, 64, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsbusIPO3cI8"
      },
      "outputs": [],
      "source": [
        "Batch_Exps1 = []\n",
        "\n",
        "for batch in batches:\n",
        "    print(f'\\n\\n Corriendo con {batch}')\n",
        "    Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, batch)\n",
        "\n",
        "    model = SmallMLP(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1)\n",
        "    if Optim_best1 == optim.SGD:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Batch_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0AYzHy73cI9"
      },
      "outputs": [],
      "source": [
        "# plot_results(EPOCHS, f'SmallMLP/Batch_Epocas-{EPOCHS}.csv', Batch_Exps1)\n",
        "plot_results(100, 'SmallMLP/Batch_Epocas-100.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amUB47Dd3cI_"
      },
      "source": [
        "## Estudio del dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Batch_best1 = 64\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, Batch_best1)\n",
        "\n",
        "dropOuts = [0.0, 0.05, 0.1] # [0.2, 0.4, 0.6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0dEi2gW3cJA"
      },
      "outputs": [],
      "source": [
        "Drop_Exps1 = []\n",
        "\n",
        "for drop in dropOuts:\n",
        "    print(f'\\n\\n Corriendo con {drop}')\n",
        "    model = SmallMLP(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1, dropout=drop)\n",
        "    if Optim_best1 == optim.SGD:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Drop_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsbJlmVA3cJA"
      },
      "outputs": [],
      "source": [
        "# plot_results(EPOCHS, f'SmallMLP/Drop_Epocas-{EPOCHS}.csv', Drop_Exps1)\n",
        "# plot_results(100, 'SmallMLP/Drop_Epocas-100.csv')\n",
        "# plot_results(EPOCHS, f'SmallMLP/Drop_Epocas-{EPOCHS}_new.csv', Drop_Exps1)\n",
        "# plot_results(100, 'SmallMLP/Drop_Epocas-100_new.csv')\n",
        "plot_results(100, 'SmallMLP/Drop_Epocas-100_full.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
