{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYg4jx_iZ3Ey"
      },
      "source": [
        "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)\n",
        "\n",
        "## Introducción al aprendizaje profundo\n",
        "\n",
        "### Trabajo práctico entregable 1/2 (materia completa)\n",
        "\n",
        "- **Estudiantes:**\n",
        "    - [Chevallier-Boutell, Ignacio José.](https://www.linkedin.com/in/nachocheva/)\n",
        "    - Gastelu, Gabriela.\n",
        "    - Santos, Maricel.\n",
        "    - Spano, Marcelo.\n",
        "\n",
        "- **Docentes:**\n",
        "    - Johanna Analiz Frau (Mercado Libre).\n",
        "    - Nindiría Armenta Guerrero (fyo).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81o1pr1wZ3E2"
      },
      "source": [
        "## Librerías y dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "SkfYanqJZ3E3",
        "outputId": "9229d5b0-bcc0-40b9-91d7-724cc177f14e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "# Configuración del dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Para que todo sea reproducible\n",
        "torch.manual_seed(1994)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTxfPCoFZ3E4"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if not IN_COLAB:\n",
        "    # Script de funciones necesarias\n",
        "    from utyls_DL import *\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n",
        "    # Dataset\n",
        "    df = pd.read_csv('diabetes_binary_5050split_health_indicators_BRFSS2015.csv')\n",
        "else:\n",
        "    # Script de funciones necesarias\n",
        "    !wget https://raw.githubusercontent.com/Cheva94/Diplo_Opt/main/3_DL/Lab1/utyls_DL.py\n",
        "    from utyls_DL import *\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n",
        "    # Dataset\n",
        "    url = 'https://raw.githubusercontent.com/Cheva94/Diplo_Opt/main/3_DL/Lab1/diabetes_binary_5050split_health_indicators_BRFSS2015.csv'\n",
        "    df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6ufcuoZ3E4"
      },
      "source": [
        "---\n",
        "# Descripción y preprocesamiento del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhY9QjkD3cIr"
      },
      "source": [
        "## Descripción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkXf37kzZ3E5"
      },
      "source": [
        "El BRFSS (Sistema de Vigilancia de Factores de Riesgo del Comportamiento) es una encuesta telefónica relacionada con la salud que los CDC (Centros para Control y prevención de Enfermedades) recopilan anualmente, desde 1984. Cada año, la encuesta recopila respuestas de más de 400.000 estadounidenses sobre conductas de riesgo relacionadas con la salud, enfermedades crónicas y el uso de servicios preventivos.\n",
        "\n",
        "Los datos que usaremos corresponden al año 2015. El dataset original consta de 441.455 personas y tiene 330 características, las cuales son preguntas formuladas directamente a los participantes o variables calculadas en función de las respuestas de los participantes. Particularmente, el csv que utilizaremos tiene ya una limpieza, quedando 70692 respuestas, donde la mitad no tienen diabetes y la otra mitad tienen prediabetes o diabetes propiamente dicha. La variable objetivo (`Diabetes_binary`) es binaria: 0 corresponde a ausencia de diabetes y 1 corresponde a prediabetes o diabetes. Además, el dataset está balanceado y consta de 21 características. Todas las variables son numéricas (de punto flotante) y no se presentan valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apPsDlraZ3E5"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "\n",
        "print('\\n\\n ###-------------------------------------### \\n Distribución de Diabetes_binary:')\n",
        "display(df['Diabetes_binary'].value_counts())\n",
        "\n",
        "print('\\n\\n ###-------------------------------------### \\n Pequeña muestra del dataset:')\n",
        "df.sample(5, random_state=1994)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPR1H0xrZ3E6"
      },
      "source": [
        "Al considerar la cantidad de valores únicos presentes en cada variable, vemos que hay 14 de las 21 características son binarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59DY16WOZ3E6"
      },
      "outputs": [],
      "source": [
        "nunique = df.nunique()\n",
        "display(nunique)\n",
        "\n",
        "cols_binary = [x for x in df.columns if (nunique[x] == 2) & (x != 'Diabetes_binary')]\n",
        "cols_non_binary = [x for x in df.columns if (x not in cols_binary) & (x != 'Diabetes_binary')]\n",
        "\n",
        "print(f'Hay {len(cols_binary)} features binarias y {len(cols_non_binary)} no binarias.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj5fnFzQZ3E7"
      },
      "source": [
        "Considerando las variables binarias, tenemos 5 que están relativamente balanceadas (`HighBP`, `HighChol`, `Smoker`, `Fruits` y `Sex`), mientras que el resto toma valores más extremos. El significado de las variables es el siguiente:\n",
        "- `HighBP`: tiene presión sanguínea alta, donde 0 es no y 1 es sí.\n",
        "- `HighChol`: tiene colesterol alto, donde 0 es no y 1 es sí.\n",
        "- `CholCheck`: se controló el colesterol en los últimos 5 años, donde 0 es no y 1 es sí.\n",
        "- `Smoker`: fumó al menos 100 cigarrillos a lo largo de su vida, donde 0 es no y 1 es sí.\n",
        "- `Stroke`: tuvo un ACV, donde 0 es no y 1 es sí.\n",
        "- `HeartDiseaseorAttack`: tiene enfermedades coronarias o ataques cardíacos, donde 0 es no y 1 es sí.\n",
        "- `PhysActivity`: realizó actividad física en los últimos 30 días, donde 0 es no y 1 es sí.\n",
        "- `Fruits`: consume al menos 1 fruta al día, donde 0 es no y 1 es sí.\n",
        "- `Veggies`: consume al menos 1 vegetal al día, donde 0 es no y 1 es sí.\n",
        "- `HvyAlcoholConsump`: consumo excesivo de alcohol (más de 14 bebidas en caso de varones o más de 7 bebidas en caso de mujeres), donde 0 es no y 1 es sí.\n",
        "- `AnyHealthcare`: posee algún tipo de cobertura médica, donde 0 es no y 1 es sí.\n",
        "- `NoDocbcCost`: tuvo la necesidad de ir al médico en el último año, pero no fue por el costo, donde 0 es no y 1 es sí.\n",
        "- `DiffWalk`: posee dificultad para caminar o subir escaleras, donde 0 es no y 1 es sí.\n",
        "- `Sex`: sexo, donde 0 es mujer y 1 es varon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe7-k1dpZ3E7"
      },
      "outputs": [],
      "source": [
        "display(df[cols_binary].mean()*100)\n",
        "\n",
        "_, axs = plt.subplots(2, 7, figsize=(35, 10))\n",
        "for cat in range(7):\n",
        "    sns.histplot(data=df, x=cols_binary[cat], ax=axs[0, cat])\n",
        "    axs[0, cat].set_ylabel('')\n",
        "    sns.histplot(data=df, x=cols_binary[cat+7], ax=axs[1, cat])\n",
        "    axs[1, cat].set_ylabel('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azrSAo0YZ3E8"
      },
      "source": [
        "Pasando ahora a las 7 características no binarias, su significado es el siguiente:\n",
        "- `BMI`: índice de masa corporal, donde debajo de 18.5 se considera por debajo del peso ideal, entre 18.5 y 24.9 es un peso saludable, de 25.0 a 29.9 es sobrepeso y por encima de 30.0 es obesidad.\n",
        "- `GenHlth`: autopercepción del estado general de salud, donde 1 es excelente, 2 es muy bueno, 3 es bueno, 4 es malo y 5 es muy malo.\n",
        "- `MentHlth`: cuántos de los últimos 30 días tuvo una mala salud mental.\n",
        "- `PhysHlth`: cuántos de los últimos 30 días tuvo una herida o enfermedad física.\n",
        "- `Age`: categorización de edades en 13 niveles, donde 1 va desde 18 hasta 24, luego toma de a 5 años hasta llegar a la categoría 13 para 80 años o más.\n",
        "- `Education`: categorización de niveles de estudio en 6 niveles, donde 1 es nunca fue a la escuela o sólo al jardín y 6 es que asistió a la universidad 4 años o más.\n",
        "- `Income`: categorización de niveles de ingreso en 8 niveles, donde 1 es menos de $ 10.000 dólares, luego toma de a $5.000 dólares hasta llegar a 8 para $75.000 o más.\n",
        "\n",
        "Vemos que `MentHlth` y `PhysHlth` presentan una dispersión de datos mucho mayor a la media. Además, el rango de valores posibles es diferente para cada una de las variables. Al comparar las distribuciones para cada variable en función de la variable objetivo, se aprecian diferencias en general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQHL4f1PZ3E8"
      },
      "outputs": [],
      "source": [
        "display(df[cols_non_binary].describe())\n",
        "\n",
        "\n",
        "_, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
        "for cat in range(4):\n",
        "    sns.kdeplot(data=df, x=cols_non_binary[cat], hue='Diabetes_binary', ax=axs[0, cat])\n",
        "    axs[0, cat].set_ylabel('')\n",
        "    axs[0, cat].grid()\n",
        "\n",
        "for cat in range(3):\n",
        "    sns.kdeplot(data=df, x=cols_non_binary[cat+4], hue='Diabetes_binary', ax=axs[1, cat])\n",
        "    axs[1, cat].set_ylabel('')\n",
        "    axs[1, cat].grid()\n",
        "\n",
        "axs[1, 3].set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH806jES3cIy"
      },
      "source": [
        "## Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tmz2Q5o3cIz"
      },
      "source": [
        "Creamos los tensores de features y target, escalando los datos entre 0 y 1 para las variables no binarias. Luego, creamos un TensorDataset a partir de los tensores de features y target. Finalmente, dividimos los datos para entrenar, validar y testear, y creamos los cargadores de datos para leer los datos por mini-batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4kPyJfR3cI0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, BATCH_SIZE)\n",
        "\n",
        "n_inputs = np.prod(np.array(Data_train[0][0].shape))\n",
        "n_outputs = df['Diabetes_binary'].nunique()\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3uO5LOp3cI1"
      },
      "source": [
        "---\n",
        "# MLP #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqQ18h673cI1"
      },
      "source": [
        "## Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmcwGhbv3cI2"
      },
      "outputs": [],
      "source": [
        "class MLP1(nn.Module):\n",
        "    '''\n",
        "    Modelo fully-connected con X capas y N neuronas por capa.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_inputs, n_outputs, n_hidden, activation_function, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.drop0 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden1 = nn.Linear(n_inputs, n_hidden)\n",
        "        self.activ1 = activation_function\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ2 = activation_function\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden3 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ3 = activation_function\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.output = nn.Linear(n_hidden, n_outputs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.drop0(x)\n",
        "\n",
        "        x = self.activ1(self.hidden1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.activ2(self.hidden2(x))\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.activ3(self.hidden3(x))\n",
        "        x = self.drop3(x)\n",
        "\n",
        "        x = self.output(x)  # Output Layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqaaTQ2R3cI3"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a9VW-Dv3cI4"
      },
      "outputs": [],
      "source": [
        "baseline_param = {\n",
        "    'nH': 5,\n",
        "    'AF': nn.Sigmoid(),\n",
        "    'GD': optim.SGD,\n",
        "    'LR': 0.1,\n",
        "    'Mom': 0.9\n",
        "}\n",
        "\n",
        "baseline_exp = []\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = MLP1(n_inputs, n_outputs, baseline_param['nH'], baseline_param['AF'])\n",
        "\n",
        "# Definimos el optimizador\n",
        "optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "\n",
        "# Corremos el baseline\n",
        "experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "baseline_exp.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yacizJ83cI5"
      },
      "outputs": [],
      "source": [
        "plot_results(baseline_exp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17fSO_O23cI5"
      },
      "source": [
        "## Estudio de la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mcn0BgA3cI6"
      },
      "outputs": [],
      "source": [
        "activation_functions = {\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU()\n",
        "}\n",
        "ActFunc_Exps1 = []\n",
        "\n",
        "for key in activation_functions.keys():\n",
        "    print(f'\\n\\n Corriendo con {key}')\n",
        "    model = MLP1(n_inputs, n_outputs, baseline_param['nH'], activation_functions[key])\n",
        "    optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    ActFunc_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SGlfm8l3cI6"
      },
      "outputs": [],
      "source": [
        "plot_results(ActFunc_Exps1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py-hG15c3cI6"
      },
      "source": [
        "## Estudio del optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bn0Qrtp3cI7"
      },
      "outputs": [],
      "source": [
        "ActFunc_best1 = None\n",
        "optims = [optim.SGD, optim.Adagrad, optim.RMSprop, optim.Adam]\n",
        "Optim_Exps1 = []\n",
        "\n",
        "for opt in optims:\n",
        "    print(f'\\n\\n Corriendo con {opt}')\n",
        "    model = MLP1(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1)\n",
        "    if opt == optim.SGD:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Optim_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIPwjc2L3cI7"
      },
      "outputs": [],
      "source": [
        "plot_results(Optim_Exps1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp66JoSR3cI7"
      },
      "source": [
        "## Estudio de la tasa de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBoOs6vV3cI8"
      },
      "outputs": [],
      "source": [
        "Optim_best1 = None\n",
        "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
        "LR_Exps1 = []\n",
        "\n",
        "for LR in alpha:\n",
        "    print(f'\\n\\n Corriendo con {LR}')\n",
        "    model = MLP1(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1)\n",
        "    if Optim_best1 == optim.SGD:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    LR_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnNDmH3B3cI8"
      },
      "outputs": [],
      "source": [
        "plot_results(LR_Exps1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWoJ8Jog3cI8"
      },
      "source": [
        "## Estudio del tamaño de lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsbusIPO3cI8"
      },
      "outputs": [],
      "source": [
        "LR_best1 = None\n",
        "batches = [32, 64, 128]\n",
        "Batch_Exps1 = []\n",
        "\n",
        "for batch in batches:\n",
        "    print(f'\\n\\n Corriendo con {batch}')\n",
        "    Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, batch)\n",
        "\n",
        "    model = MLP1(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1)\n",
        "    if Optim_best1 == optim.SGD:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Batch_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0AYzHy73cI9"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amUB47Dd3cI_"
      },
      "source": [
        "## Estudio del dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0dEi2gW3cJA"
      },
      "outputs": [],
      "source": [
        "Batch_best1 = None\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, Batch_best1)\n",
        "\n",
        "dropOuts = [0.2, 0.4, 0.6]\n",
        "Drop_Exps1 = []\n",
        "\n",
        "for drop in dropOuts:\n",
        "    print(f'\\n\\n Corriendo con {drop}')\n",
        "    model = MLP1(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best1, dropout=drop)\n",
        "    if Optim_best1 == optim.SGD:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best1(model.parameters(), lr=LR_best1)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Drop_Exps1.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsbJlmVA3cJA"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOUVZWJD3cJA"
      },
      "source": [
        "---\n",
        "# MLP #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKQTPSs03cJQ"
      },
      "source": [
        "## Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUgmDVGe3cJQ"
      },
      "outputs": [],
      "source": [
        "class MLP2(nn.Module):\n",
        "    '''\n",
        "    Modelo fully-connected con X capas y N neuronas por capa.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_inputs, n_outputs, n_hidden, activation_function, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.drop0 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden1 = nn.Linear(n_inputs, n_hidden)\n",
        "        self.activ1 = activation_function\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ2 = activation_function\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden3 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ3 = activation_function\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.output = nn.Linear(n_hidden, n_outputs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.drop0(x)\n",
        "\n",
        "        x = self.activ1(self.hidden1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.activ2(self.hidden2(x))\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.activ3(self.hidden3(x))\n",
        "        x = self.drop3(x)\n",
        "\n",
        "        x = self.output(x)  # Output Layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zOiNJGE3cJQ"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAj1tOmd3cJR"
      },
      "outputs": [],
      "source": [
        "baseline_param = {\n",
        "    'nH': 5,\n",
        "    'AF': nn.Sigmoid(),\n",
        "    'GD': optim.SGD,\n",
        "    'LR': 0.1,\n",
        "    'Mom': 0.9\n",
        "}\n",
        "\n",
        "baseline_exp = []\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = MLP2(n_inputs, n_outputs, baseline_param['nH'], baseline_param['AF'])\n",
        "\n",
        "# Definimos el optimizador\n",
        "optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "\n",
        "# Corremos el baseline\n",
        "experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "baseline_exp.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xKZICop3cJR"
      },
      "outputs": [],
      "source": [
        "plot_results(baseline_exp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnirhWVD3cJR"
      },
      "source": [
        "## Estudio de la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr5x-kOE3cJR"
      },
      "outputs": [],
      "source": [
        "activation_functions = {\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU()\n",
        "}\n",
        "ActFunc_Exps2 = []\n",
        "\n",
        "for key in activation_functions.keys():\n",
        "    print(f'\\n\\n Corriendo con {key}')\n",
        "    model = MLP2(n_inputs, n_outputs, baseline_param['nH'], activation_functions[key])\n",
        "    optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    ActFunc_Exps2.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGeInVcg3cJS"
      },
      "outputs": [],
      "source": [
        "plot_results(ActFunc_Exps2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGMEDYZo3cJS"
      },
      "source": [
        "## Estudio del optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-W8aI163cJS"
      },
      "outputs": [],
      "source": [
        "ActFunc_best2 = None\n",
        "optims = [optim.SGD, optim.Adagrad, optim.RMSprop, optim.Adam]\n",
        "Optim_Exps2 = []\n",
        "\n",
        "for opt in optims:\n",
        "    print(f'\\n\\n Corriendo con {opt}')\n",
        "    model = MLP2(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best2)\n",
        "    if opt == optim.SGD:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Optim_Exps2.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZVCJZ0u3cJT"
      },
      "outputs": [],
      "source": [
        "plot_results(Optim_Exps2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTjc7_-13cJT"
      },
      "source": [
        "## Estudio de la tasa de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3DKzDaw3cJU"
      },
      "outputs": [],
      "source": [
        "Optim_best2 = None\n",
        "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
        "LR_Exps2 = []\n",
        "\n",
        "for LR in alpha:\n",
        "    print(f'\\n\\n Corriendo con {LR}')\n",
        "    model = MLP2(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best2)\n",
        "    if Optim_best2 == optim.SGD:\n",
        "        optimizer = Optim_best2(model.parameters(), lr=LR, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best2(model.parameters(), lr=LR)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    LR_Exps2.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS4TLnCs3cJV"
      },
      "outputs": [],
      "source": [
        "plot_results(LR_Exps2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvgDUhyP3cJW"
      },
      "source": [
        "## Estudio del tamaño de lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jSOlk473cJW"
      },
      "outputs": [],
      "source": [
        "LR_best2 = None\n",
        "batches = [32, 64, 128]\n",
        "Batch_Exps2 = []\n",
        "\n",
        "for batch in batches:\n",
        "    print(f'\\n\\n Corriendo con {batch}')\n",
        "    Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, batch)\n",
        "\n",
        "    model = MLP2(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best2)\n",
        "    if Optim_best2 == optim.SGD:\n",
        "        optimizer = Optim_best2(model.parameters(), lr=LR_best2, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best2(model.parameters(), lr=LR_best2)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Batch_Exps2.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aoT8_pf3cJX"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVUR55lR3cJX"
      },
      "source": [
        "## Estudio del dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLQ9TW-i3cJY"
      },
      "outputs": [],
      "source": [
        "Batch_best2 = None\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, Batch_best2)\n",
        "\n",
        "dropOuts = [0.2, 0.4, 0.6]\n",
        "Drop_Exps2 = []\n",
        "\n",
        "for drop in dropOuts:\n",
        "    print(f'\\n\\n Corriendo con {drop}')\n",
        "    model = MLP2(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best2, dropout=drop)\n",
        "    if Optim_best2 == optim.SGD:\n",
        "        optimizer = Optim_best2(model.parameters(), lr=LR_best2, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best2(model.parameters(), lr=LR_best2)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Drop_Exps2.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbC0bSSj3cJZ"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi_uqSmC3cJZ"
      },
      "source": [
        "---\n",
        "# MLP #3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5aZKout3cJZ"
      },
      "source": [
        "## Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7JNmkwy3cJa"
      },
      "outputs": [],
      "source": [
        "class MLP3(nn.Module):\n",
        "    '''\n",
        "    Modelo fully-connected con X capas y N neuronas por capa.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_inputs, n_outputs, n_hidden, activation_function, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.drop0 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden1 = nn.Linear(n_inputs, n_hidden)\n",
        "        self.activ1 = activation_function\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ2 = activation_function\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden3 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ3 = activation_function\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.output = nn.Linear(n_hidden, n_outputs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.drop0(x)\n",
        "\n",
        "        x = self.activ1(self.hidden1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.activ2(self.hidden2(x))\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.activ3(self.hidden3(x))\n",
        "        x = self.drop3(x)\n",
        "\n",
        "        x = self.output(x)  # Output Layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhKzhnKl3cJa"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKnk63rF3cJa"
      },
      "outputs": [],
      "source": [
        "baseline_param = {\n",
        "    'nH': 5,\n",
        "    'AF': nn.Sigmoid(),\n",
        "    'GD': optim.SGD,\n",
        "    'LR': 0.1,\n",
        "    'Mom': 0.9\n",
        "}\n",
        "\n",
        "baseline_exp = []\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = MLP3(n_inputs, n_outputs, baseline_param['nH'], baseline_param['AF'])\n",
        "\n",
        "# Definimos el optimizador\n",
        "optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "\n",
        "# Corremos el baseline\n",
        "experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "baseline_exp.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmGwGSN03cJb"
      },
      "outputs": [],
      "source": [
        "plot_results(baseline_exp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJwhenIG3cJb"
      },
      "source": [
        "## Estudio de la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhaysP1g3cJb"
      },
      "outputs": [],
      "source": [
        "activation_functions = {\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU()\n",
        "}\n",
        "ActFunc_Exps3 = []\n",
        "\n",
        "for key in activation_functions.keys():\n",
        "    print(f'\\n\\n Corriendo con {key}')\n",
        "    model = MLP3(n_inputs, n_outputs, baseline_param['nH'], activation_functions[key])\n",
        "    optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    ActFunc_Exps3.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upeiCjkE3cJc"
      },
      "outputs": [],
      "source": [
        "plot_results(ActFunc_Exps3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W73HSEoe3cJc"
      },
      "source": [
        "## Estudio del optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgVILtEz3cJc"
      },
      "outputs": [],
      "source": [
        "ActFunc_best3 = None\n",
        "optims = [optim.SGD, optim.Adagrad, optim.RMSprop, optim.Adam]\n",
        "Optim_Exps3 = []\n",
        "\n",
        "for opt in optims:\n",
        "    print(f'\\n\\n Corriendo con {opt}')\n",
        "    model = MLP3(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best3)\n",
        "    if opt == optim.SGD:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Optim_Exps3.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8587pky3cJc"
      },
      "outputs": [],
      "source": [
        "plot_results(Optim_Exps3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjYKTxiN3cJd"
      },
      "source": [
        "## Estudio de la tasa de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK0zsnmw3cJd"
      },
      "outputs": [],
      "source": [
        "Optim_best3 = None\n",
        "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
        "LR_Exps3 = []\n",
        "\n",
        "for LR in alpha:\n",
        "    print(f'\\n\\n Corriendo con {LR}')\n",
        "    model = MLP3(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best3)\n",
        "    if Optim_best3 == optim.SGD:\n",
        "        optimizer = Optim_best3(model.parameters(), lr=LR, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best3(model.parameters(), lr=LR)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    LR_Exps3.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThxGN-vC3cJd"
      },
      "outputs": [],
      "source": [
        "plot_results(LR_Exps3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZ-Qy4h3cJe"
      },
      "source": [
        "## Estudio del tamaño de lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHs0fbn53cJe"
      },
      "outputs": [],
      "source": [
        "LR_best3 = None\n",
        "batches = [32, 64, 128]\n",
        "Batch_Exps3 = []\n",
        "\n",
        "for batch in batches:\n",
        "    print(f'\\n\\n Corriendo con {batch}')\n",
        "    Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, batch)\n",
        "\n",
        "    model = MLP3(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best3)\n",
        "    if Optim_best3 == optim.SGD:\n",
        "        optimizer = Optim_best3(model.parameters(), lr=LR_best3, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best3(model.parameters(), lr=LR_best3)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Batch_Exps3.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGo0pfu_3cJe"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9u_w2wr3cJf"
      },
      "source": [
        "## Estudio del dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eqv35I13cJf"
      },
      "outputs": [],
      "source": [
        "Batch_best3 = None\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, Batch_best3)\n",
        "\n",
        "dropOuts = [0.2, 0.4, 0.6]\n",
        "Drop_Exps3 = []\n",
        "\n",
        "for drop in dropOuts:\n",
        "    print(f'\\n\\n Corriendo con {drop}')\n",
        "    model = MLP3(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best3, dropout=drop)\n",
        "    if Optim_best3 == optim.SGD:\n",
        "        optimizer = Optim_best3(model.parameters(), lr=LR_best3, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best3(model.parameters(), lr=LR_best3)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Drop_Exps3.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKNNoZL43cJg"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoKa1buH3cJg"
      },
      "source": [
        "---\n",
        "# MLP #4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNmxnwcs3cJh"
      },
      "source": [
        "## Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZVA0T7c3cJh"
      },
      "outputs": [],
      "source": [
        "class MLP4(nn.Module):\n",
        "    '''\n",
        "    Modelo fully-connected con X capas y N neuronas por capa.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_inputs, n_outputs, n_hidden, activation_function, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.drop0 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden1 = nn.Linear(n_inputs, n_hidden)\n",
        "        self.activ1 = activation_function\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ2 = activation_function\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden3 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.activ3 = activation_function\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.output = nn.Linear(n_hidden, n_outputs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.drop0(x)\n",
        "\n",
        "        x = self.activ1(self.hidden1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.activ2(self.hidden2(x))\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.activ3(self.hidden3(x))\n",
        "        x = self.drop3(x)\n",
        "\n",
        "        x = self.output(x)  # Output Layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjtXl6Qz3cJh"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH7tizor3cJi"
      },
      "outputs": [],
      "source": [
        "baseline_param = {\n",
        "    'nH': 5,\n",
        "    'AF': nn.Sigmoid(),\n",
        "    'GD': optim.SGD,\n",
        "    'LR': 0.1,\n",
        "    'Mom': 0.9\n",
        "}\n",
        "\n",
        "baseline_exp = []\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = MLP4(n_inputs, n_outputs, baseline_param['nH'], baseline_param['AF'])\n",
        "\n",
        "# Definimos el optimizador\n",
        "optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "\n",
        "# Corremos el baseline\n",
        "experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "baseline_exp.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNPiOO-n3cJi"
      },
      "outputs": [],
      "source": [
        "plot_results(baseline_exp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tu1jeZR3cJi"
      },
      "source": [
        "## Estudio de la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URSt4BhN3cJi"
      },
      "outputs": [],
      "source": [
        "activation_functions = {\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'LeakyReLU': nn.LeakyReLU()\n",
        "}\n",
        "ActFunc_Exps4 = []\n",
        "\n",
        "for key in activation_functions.keys():\n",
        "    print(f'\\n\\n Corriendo con {key}')\n",
        "    model = MLP4(n_inputs, n_outputs, baseline_param['nH'], activation_functions[key])\n",
        "    optimizer = baseline_param['GD'](model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    ActFunc_Exps4.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQgRWTEV3cJj"
      },
      "outputs": [],
      "source": [
        "plot_results(ActFunc_Exps4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZOiigZe3cJj"
      },
      "source": [
        "## Estudio del optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDZmJIvg3cJj"
      },
      "outputs": [],
      "source": [
        "ActFunc_best4 = None\n",
        "optims = [optim.SGD, optim.Adagrad, optim.RMSprop, optim.Adam]\n",
        "Optim_Exps4 = []\n",
        "\n",
        "for opt in optims:\n",
        "    print(f'\\n\\n Corriendo con {opt}')\n",
        "    model = MLP4(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best4)\n",
        "    if opt == optim.SGD:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'], momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = opt(model.parameters(), lr=baseline_param['LR'])\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Optim_Exps4.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ley20Ptm3cJk"
      },
      "outputs": [],
      "source": [
        "plot_results(Optim_Exps4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvMtJxAh3cJl"
      },
      "source": [
        "## Estudio de la tasa de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fte7W3ps3cJm"
      },
      "outputs": [],
      "source": [
        "Optim_best4 = None\n",
        "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
        "LR_Exps4 = []\n",
        "\n",
        "for LR in alpha:\n",
        "    print(f'\\n\\n Corriendo con {LR}')\n",
        "    model = MLP4(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best4)\n",
        "    if Optim_best4 == optim.SGD:\n",
        "        optimizer = Optim_best4(model.parameters(), lr=LR, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best4(model.parameters(), lr=LR)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    LR_Exps4.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLpSZksb3cJn"
      },
      "outputs": [],
      "source": [
        "plot_results(LR_Exps4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVmPiUDP3cJo"
      },
      "source": [
        "## Estudio del tamaño de lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whQagTjO3cJp"
      },
      "outputs": [],
      "source": [
        "LR_best4 = None\n",
        "batches = [32, 64, 128]\n",
        "Batch_Exps4 = []\n",
        "\n",
        "for batch in batches:\n",
        "    print(f'\\n\\n Corriendo con {batch}')\n",
        "    Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, batch)\n",
        "\n",
        "    model = MLP4(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best4)\n",
        "    if Optim_best4 == optim.SGD:\n",
        "        optimizer = Optim_best4(model.parameters(), lr=LR_best4, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best4(model.parameters(), lr=LR_best4)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Batch_Exps4.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKERO8Pj3cJp"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJmUD7Q3cJq"
      },
      "source": [
        "## Estudio del dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8vt0ffx3cJq"
      },
      "outputs": [],
      "source": [
        "Batch_best4 = None\n",
        "Data_train, Data_val, Data_test, Load_train, Load_val, Load_test = preproc(df, cols_binary, cols_non_binary, Batch_best4)\n",
        "\n",
        "dropOuts = [0.2, 0.4, 0.6]\n",
        "Drop_Exps4 = []\n",
        "\n",
        "for drop in dropOuts:\n",
        "    print(f'\\n\\n Corriendo con {drop}')\n",
        "    model = MLP4(n_inputs, n_outputs, baseline_param['nH'], ActFunc_best4, dropout=drop)\n",
        "    if Optim_best4 == optim.SGD:\n",
        "        optimizer = Optim_best4(model.parameters(), lr=LR_best4, momentum=baseline_param['Mom'])\n",
        "    else:\n",
        "        optimizer = Optim_best4(model.parameters(), lr=LR_best4)\n",
        "    experiment = run_experiment(model, EPOCHS, Load_train, Load_val, loss_function, optimizer, device, use_tqdm=False)\n",
        "    Drop_Exps4.append(experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHdDNJpe3cJq"
      },
      "outputs": [],
      "source": [
        "plot_results(Batch_Exps4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLd6QxJi3cJr"
      },
      "source": [
        "---\n",
        "# Comparación final y conclusiones\n",
        "\n",
        "Acá comparar la mejor configuración de los 3 modelos elegidos y aplicarlos al conjunto de test? O ir testeando al final de cada modelo?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
